{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competición Leaf de kaggle\n",
    "\n",
    "Para realizar este ejercicio es necesario descargarse de kaggle los archivos train.csv y test.csv desde la seccion de la competicion: https://www.kaggle.com/c/leaf-classification.\n",
    "\n",
    "Cargamos, en primer lugar, el archivo train.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('data/leaf/train.csv')\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 194 columnas, 1 de ellas (species) es las variable de clasificación.\n",
    "\n",
    "Con **describe** obtenemos estadísticas básicas del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos la varible de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    99\n",
       "mean     10\n",
       "std       0\n",
       "min      10\n",
       "25%      10\n",
       "50%      10\n",
       "75%      10\n",
       "max      10\n",
       "Name: species, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.species.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*count* nos indica que tenemos 99 clases diferentes\n",
    "*mean* que tenemos 10 muestras de cada clase (no muchas)\n",
    "\n",
    "Nos vamos definir las variables globales TARGET (variable de clasificación) y TRAIN_COLUMNS (aquellas variables que vamos a utilizar para entrenar el modelo). De TRAIN_COLUMNS, al menos, deberemos excluir el *id* y la variable de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'species'\n",
    "TRAIN_COLUMNS = [c for c in train.columns \n",
    "                     if not c in ['id', 'species']]\n",
    "\n",
    "X = train[TRAIN_COLUMNS]\n",
    "y = train[[TARGET]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos vamos a definir tambíen una variable para guardar el algoritmo que vamos a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ESTIMATOR = LogisticRegression(random_state=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acer_Capillipes',\n",
       " 'Acer_Circinatum',\n",
       " 'Acer_Mono',\n",
       " 'Acer_Opalus',\n",
       " 'Acer_Palmatum',\n",
       " 'Acer_Pictum',\n",
       " 'Acer_Platanoids',\n",
       " 'Acer_Rubrum',\n",
       " 'Acer_Rufinerve',\n",
       " 'Acer_Saccharinum',\n",
       " 'Alnus_Cordata',\n",
       " 'Alnus_Maximowiczii',\n",
       " 'Alnus_Rubra',\n",
       " 'Alnus_Sieboldiana',\n",
       " 'Alnus_Viridis',\n",
       " 'Arundinaria_Simonii',\n",
       " 'Betula_Austrosinensis',\n",
       " 'Betula_Pendula',\n",
       " 'Callicarpa_Bodinieri',\n",
       " 'Castanea_Sativa',\n",
       " 'Celtis_Koraiensis',\n",
       " 'Cercis_Siliquastrum',\n",
       " 'Cornus_Chinensis',\n",
       " 'Cornus_Controversa',\n",
       " 'Cornus_Macrophylla',\n",
       " 'Cotinus_Coggygria',\n",
       " 'Crataegus_Monogyna',\n",
       " 'Cytisus_Battandieri',\n",
       " 'Eucalyptus_Glaucescens',\n",
       " 'Eucalyptus_Neglecta',\n",
       " 'Eucalyptus_Urnigera',\n",
       " 'Fagus_Sylvatica',\n",
       " 'Ginkgo_Biloba',\n",
       " 'Ilex_Aquifolium',\n",
       " 'Ilex_Cornuta',\n",
       " 'Liquidambar_Styraciflua',\n",
       " 'Liriodendron_Tulipifera',\n",
       " 'Lithocarpus_Cleistocarpus',\n",
       " 'Lithocarpus_Edulis',\n",
       " 'Magnolia_Heptapeta',\n",
       " 'Magnolia_Salicifolia',\n",
       " 'Morus_Nigra',\n",
       " 'Olea_Europaea',\n",
       " 'Phildelphus',\n",
       " 'Populus_Adenopoda',\n",
       " 'Populus_Grandidentata',\n",
       " 'Populus_Nigra',\n",
       " 'Prunus_Avium',\n",
       " 'Prunus_X_Shmittii',\n",
       " 'Pterocarya_Stenoptera',\n",
       " 'Quercus_Afares',\n",
       " 'Quercus_Agrifolia',\n",
       " 'Quercus_Alnifolia',\n",
       " 'Quercus_Brantii',\n",
       " 'Quercus_Canariensis',\n",
       " 'Quercus_Castaneifolia',\n",
       " 'Quercus_Cerris',\n",
       " 'Quercus_Chrysolepis',\n",
       " 'Quercus_Coccifera',\n",
       " 'Quercus_Coccinea',\n",
       " 'Quercus_Crassifolia',\n",
       " 'Quercus_Crassipes',\n",
       " 'Quercus_Dolicholepis',\n",
       " 'Quercus_Ellipsoidalis',\n",
       " 'Quercus_Greggii',\n",
       " 'Quercus_Hartwissiana',\n",
       " 'Quercus_Ilex',\n",
       " 'Quercus_Imbricaria',\n",
       " 'Quercus_Infectoria_sub',\n",
       " 'Quercus_Kewensis',\n",
       " 'Quercus_Nigra',\n",
       " 'Quercus_Palustris',\n",
       " 'Quercus_Phellos',\n",
       " 'Quercus_Phillyraeoides',\n",
       " 'Quercus_Pontica',\n",
       " 'Quercus_Pubescens',\n",
       " 'Quercus_Pyrenaica',\n",
       " 'Quercus_Rhysophylla',\n",
       " 'Quercus_Rubra',\n",
       " 'Quercus_Semecarpifolia',\n",
       " 'Quercus_Shumardii',\n",
       " 'Quercus_Suber',\n",
       " 'Quercus_Texana',\n",
       " 'Quercus_Trojana',\n",
       " 'Quercus_Variabilis',\n",
       " 'Quercus_Vulcanica',\n",
       " 'Quercus_x_Hispanica',\n",
       " 'Quercus_x_Turneri',\n",
       " 'Rhododendron_x_Russellianum',\n",
       " 'Salix_Fragilis',\n",
       " 'Salix_Intergra',\n",
       " 'Sorbus_Aria',\n",
       " 'Tilia_Oliveri',\n",
       " 'Tilia_Platyphyllos',\n",
       " 'Tilia_Tomentosa',\n",
       " 'Ulmus_Bergmanniana',\n",
       " 'Viburnum_Tinus',\n",
       " 'Viburnum_x_Rhytidophylloides',\n",
       " 'Zelkova_Serrata']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(train.species) \n",
    "y = le.transform(train.species)           # encode species strings\n",
    "classes = list(le.classes_) \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2016, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATOR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01063669,  0.01344462,  0.00965552, ...,  0.00728016,\n",
       "         0.00764327,  0.01294914],\n",
       "       [ 0.0084319 ,  0.00931848,  0.00871455, ...,  0.00754165,\n",
       "         0.00817185,  0.00941171],\n",
       "       [ 0.01079442,  0.01144427,  0.00911849, ...,  0.0076757 ,\n",
       "         0.00792944,  0.0100895 ],\n",
       "       ..., \n",
       "       [ 0.009243  ,  0.01030211,  0.00840652, ...,  0.00731508,\n",
       "         0.00985176,  0.00958918],\n",
       "       [ 0.01110626,  0.01230008,  0.00811379, ...,  0.00732597,\n",
       "         0.00841908,  0.0106242 ],\n",
       "       [ 0.01142712,  0.01296547,  0.00817202, ...,  0.00721551,\n",
       "         0.00854942,  0.01141994]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATOR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*predict_proba* nos devuelve la probabilidad de que la muestra pertenezca a cada una de las clases. Dicha matriz de predicciones tendrá una dimension (nº de muestras, nº de clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 99)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATOR.predict_proba(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 92, 99. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 0  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 49 50 51 52\n 53 54 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 74 75 76 77 78 80\n 81 82 83 84 85 86 88 89 90 91 92 93 94 95 96 97 98]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-598058f0b179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# The mean squared error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print(\"\\tError Log-loss: %.2f\" % log_loss(y_test, \n\u001b[1;32m----> 4\u001b[1;33m                                 ESTIMATOR.predict_proba(X_test)))\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   1652\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[0;32m   1653\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m                                                   lb.classes_))\n\u001b[0m\u001b[0;32m   1655\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 92, 99. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 0  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 49 50 51 52\n 53 54 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 74 75 76 77 78 80\n 81 82 83 84 85 86 88 89 90 91 92 93 94 95 96 97 98]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "# The mean squared error\n",
    "print(\"\\tError Log-loss: %.2f\" % log_loss(y_test, \n",
    "                                ESTIMATOR.predict_proba(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este error es debido a que al dividir nuestros datos en entrenamiento y prueba (train y test) en el test han caido menos menos clases de las que tenemos en el train. Para solucionar este problema podemos indicar a la función *train_test_split* que asegure que hay muestras representativas de todas las clases en ambos conjuntos con el parámetro *stratify*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tError Log-loss: 4.24\n"
     ]
    }
   ],
   "source": [
    "ESTIMATOR.fit(X_train[TRAIN_COLUMNS], y_train)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "# The mean squared error\n",
    "print(\"\\tError Log-loss: %.2f\" % log_loss(y_test, \n",
    "                                          ESTIMATOR.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos modificar los parámetros para intentar que nuestro modelo se ajuste mejor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tError Log-loss: 0.34\n"
     ]
    }
   ],
   "source": [
    "#'tol': [0.001, 0.0001, 0.005]\n",
    "ESTIMATOR = LogisticRegression(C=200000, \n",
    "                        tol=0.006,\n",
    "                        solver='newton-cg', \n",
    "                        multi_class='multinomial')\n",
    "ESTIMATOR.fit(X_train[TRAIN_COLUMNS], y_train)\n",
    "# The mean squared error\n",
    "print(\"\\tError Log-loss: %.2f\" % log_loss(y_test, \n",
    "                                          ESTIMATOR.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos probar otros algoritmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tError Log-loss: 3.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            max_depth=10, \n",
    "                            min_samples_split=0.6, \n",
    "                            min_samples_leaf=1,\n",
    "                            random_state=2016)\n",
    "rf.fit(X_train[TRAIN_COLUMNS], y_train)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"\\tError Log-loss: %.2f\" % \n",
    "      log_loss(y_test, rf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del fichero de predicciones\n",
    "\n",
    "Una vez que tenemos nuestro modelo entrenado podemos crear el fichero de predicciones para subir a kaggle. Para ello, volvemos a entrenar el modelo con todos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.16916807e-09,   1.49113286e-09,   2.82254873e-11, ...,\n",
       "          1.25319107e-08,   2.46346158e-09,   1.07865839e-09],\n",
       "       [  4.18831203e-08,   9.31506332e-08,   5.19919184e-08, ...,\n",
       "          6.37082116e-06,   7.38320586e-09,   8.57723986e-06],\n",
       "       [  8.95528879e-09,   9.98873577e-01,   2.94284305e-07, ...,\n",
       "          7.24897742e-10,   1.28457768e-11,   6.99317173e-04],\n",
       "       ..., \n",
       "       [  2.42146292e-06,   3.42388599e-08,   1.89033884e-08, ...,\n",
       "          1.60553177e-07,   5.39558690e-10,   1.95781704e-07],\n",
       "       [  2.34628130e-08,   1.75817581e-08,   7.35651968e-07, ...,\n",
       "          2.27847517e-09,   2.22342976e-09,   8.36107556e-09],\n",
       "       [  3.78195026e-14,   9.47853961e-10,   1.05472736e-11, ...,\n",
       "          1.55279213e-11,   2.96456414e-13,   2.39866438e-10]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATOR.fit(X[TRAIN_COLUMNS], y)\n",
    "\n",
    "test = pd.read_csv('data/leaf/test.csv')\n",
    "\n",
    "ESTIMATOR.predict_proba(test[TRAIN_COLUMNS])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el archivo de test y calculamos las predicciones del model para estos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/leaf/test.csv')\n",
    "\n",
    "predictions = ESTIMATOR.predict_proba(test[TRAIN_COLUMNS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimos construimos un nuevo dataset, unión de las predicciones y la columna *id*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame(data=predictions, columns=classes)\n",
    "\n",
    "subm = pd.concat((test, subm), axis=1)[['id'] + classes]\n",
    "#subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo guardamos, indicando no nos incluya la columnas *index* del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv(\"subm_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la validación cruzada pretendemos determinar si nuestro modelo es suficientemente generalista.\n",
    "\n",
    "Como vimos anteriormente tenemos que usar versión estratificada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(y, 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *cross_val_score* creará ajustará un modelo por cada fold (en este caso 5 modelos) y calculará el error cometido. \n",
    "\n",
    "Tenemos que indicar los folds y la métrica que queremos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.20989388, -0.21531911, -0.27423294, -0.17801408])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "results = cross_val_score(ESTIMATOR, X, y, cv=kfold, \n",
    "                          scoring='log_loss')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular el error medio y la deviación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio: -0.219\n",
      "Desviación: 0.035\n"
     ]
    }
   ],
   "source": [
    "print(\"Error medio: %0.3f\" % np.mean(results) )\n",
    "print(\"Desviación: %0.3f\" % np.std(results) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de parametros con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X[TRAIN_COLUMNS])\n",
    "\n",
    "\n",
    "params = {'C':[1, 10, 50, 100, 500, 1000, 2000, 200000], \n",
    "          'tol': [0.001, 0.0001, 0.005, 0.006]}\n",
    "log_reg = LogisticRegression(solver='newton-cg', \n",
    "                             multi_class='multinomial')\n",
    "clf = GridSearchCV(log_reg, params, scoring='log_loss', \n",
    "                   refit='True', n_jobs=12, cv=5)\n",
    "clf.fit(scaler.transform(X[TRAIN_COLUMNS]), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
